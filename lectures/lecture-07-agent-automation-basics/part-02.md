# Part 2. LLM의 작동 원리와 한계 이해

## 슬라이드 1: Part 2 타이틀

```markdown
<!-- _class: lead -->

![bg left:35%](images/img_2_1_llm_brain.svg)

# Part 2

LLM의 작동 원리와 한계 이해

---
```

## 슬라이드 2: LLM은 정말 '생각'하는가?

```markdown
![bg left:35%](images/img_2_1_llm_brain.svg)

# LLM은 정말 '생각'하는가?

**직관적 느낌:**
- 자연스러운 대화
- 복잡한 문제 해결
- 창의적인 제안

**실제로는:**
- 패턴 인식 기계
- 확률 기반 예측
- 학습 데이터의 통계적 조합

**중요:** 이해하고 쓰는 것 vs 모르고 쓰는 것

---
```

## 슬라이드 3: 토큰, 확률, 다음 단어 예측

```markdown
# LLM의 작동 방식

## 토큰 (Token)

단어나 문자의 작은 단위

"안녕하세요" → ["안녕", "하", "세요"] (약 3-4 토큰)

## 확률 기반 예측

"오늘 날씨가 ___"
- "좋다" (40%)
- "맑다" (25%)
- "흐리다" (20%)
- "춥다" (15%)

## 컨텍스트 윈도우

Claude: 약 200K 토큰 (영문 기준 약 15만 단어)

---
```

## 슬라이드 4: 컨텍스트의 중요성

```markdown
![bg left:35%](images/img_3_2_context.svg)

# 컨텍스트의 중요성

## 같은 질문, 다른 답변

**컨텍스트 없음:**
"함수 만들어줘" → ???

**컨텍스트 있음:**
"Python으로 두 수를 더하는 함수를 만들어줘" → ✓

## LLM의 특성

비어있는 컨텍스트를 자기가 알아서 채움
→ 예상치 못한 결과

**핵심:** 컨텍스트를 명확히 제공해야 함

---
```

## 슬라이드 5: Agent 구조

```markdown
![bg left:35%](images/img_2_2_agent_structure.svg)

# Agent 구조

## LLM (Large Language Model)

핵심 언어 처리 엔진

## Tool (도구)

파일 읽기/쓰기, 코드 실행, 검색 등

## Memory (기억)

대화 히스토리, 컨텍스트 유지

## Planning (계획)

작업 분해, 단계별 실행

**Agent = LLM + Tools + Memory + Planning**

---
```

## 슬라이드 6: Claude Code CLI의 특별함

```markdown
# Claude Code CLI의 특별함

| 일반 Chatbot | Claude Code CLI |
|-------------|-----------------|
| 대화만 가능 | 파일 읽기/쓰기 |
| 정보만 제공 | 실제 작업 수행 |
| 단발성 | 지속적 컨텍스트 |
| 계획 없음 | **Plan 모드** |

## Plan 모드의 힘

1. 작업 이해 및 분석
2. 단계별 계획 수립
3. 사용자 확인
4. 실행

**→ 예측 가능하고 안전한 자동화**

---
```

## 슬라이드 7: 한계 인정하기

```markdown
# LLM과 Agent의 한계

## 환각 (Hallucination)

없는 정보를 그럴듯하게 만들어냄

## 일관성

같은 질문에 다른 답변

## 컨텍스트 제약

200K 토큰 한도 (대용량 프로젝트 어려움)

## 최신 정보 부족

학습 데이터 기준 이후 정보 모름

**→ 항상 검증하고, 확인하고, 테스트하기**

---
```

## 슬라이드 8: Part 2 정리

```markdown
# Part 2 정리

**핵심 메시지:**

1. LLM은 '생각'하지 않음, 패턴 인식 기계
2. 컨텍스트가 핵심 - 비어있으면 예측 불가
3. Agent = LLM + Tools + Memory + Planning
4. Claude Code CLI의 Plan 모드가 강력함
5. 한계를 인정하고 검증 필수

**다음 Part:**

계획: 컨텍스트를 채우는 기술 + 실습

---
```
